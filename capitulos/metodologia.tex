%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla TFG/TFM
% Escuela Polit√©cnica Superior de la Universidad de Alicante
% Realizado por: Jose Manuel Requena Plens
% Contacto: info@jmrplens.com / Telegram:@jmrplens
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Materials and Methods}
\label{metodologia}

\textit{In this chapter we go over the different materials and methods that were considered in this work. It is organized as follows: Section \ref{sec:software} analyzes some of the software specification used in this thesis, focusing on the 3D Game engine framework and working environments. Then, in Section \ref{sec:hardware} we present our hardware equipment used for this work.}

\section{Software}
\label{sec:software}
In order to carry out this project, it was necessary to carefully choose our working environments and programming tools, in this Section, we go through some of our software of choice as well as giving a brief explanation on why they were chosen.

\subsection{Unreal Engine 4}
\gls{ue4} is a very powerful, highly portable game engine, written in C++ and developed by Epic Games\footnote{\url{https://www.unrealengine.com/en-US/}}.
The main advantages \gls{ue4} offers over other game engines and the reason UnrealROX was built using it are listed as follows:

\begin{itemize}
	\item \textbf{Virtual reality support:} VR was a key point when developing the ROX framework since one of the main goals was to allow the user to completely interact with the environment.
	\item \textbf{Photorealism:} Realism is a key factor when it comes to synthetic data and the potential of \gls{ue4} to run extremely realistic scenes, such as the one shown in Figure \ref{fig:london_apartment}, in real time made it suitable for this purpose.
	\item \textbf{Blueprints:} Blueprints are one of the tools that \gls{ue4} offers, they  allow for quick behavior definitions within the editor. This makes it apt for prototyping and testing.
	\item \textbf{Community:} \gls{ue4} is currently one of the most popular game engines and it has a rather populous community, the official forums and other platforms are very active and the documentation is well maintained. The developing team is heavily involved and they continuously release new versions and bug fixes. 
\end{itemize}

\begin{figure}[h]
	\includegraphics[scale=0.2]{archivos/london_apartment.png}
	\centering
	\caption[Snapshot of the Viennese Apartment by UE4Arch]{Snapshot of the Viennese Apartment by UE4Arch\footnotemark}
	\label{fig:london_apartment}
\end{figure}
\footnotetext{\url{https://ue4arch.com/projects/viennese-apartment/}}

\subsection{Visual Studio 2017}
Visual Studio is an \gls{ide} developed by Microsoft and used for software development. It supports a variety of programming languages, although it mainly focuses on C++, C\# and the .NET framework. It includes a code editor, file browser and debugger. It also includes plugins, support for syntax highlighting and integration with IntelliSense, which allows for code completion, quick information of variables and methods, amongst other features.

However, the main reason Visual Studio was chosen as the main \gls{ide} for this project is the integration with \gls{ue4}. The \gls{ue4} editor has options to quickly visualize any object from the context menu or the scene in Visual Studio, allowing to make quick changes, recompile and launch in very little time.

\begin{figure}[h]
	\includegraphics[width=0.7\textwidth]{archivos/vs_ide.png}
	\centering
	\caption{Visual Studio IDE.}
	\label{fig:visual_studio}
\end{figure}

\subsection{Google Colab}
\label{sec:colab}
Google Colaboratory\footnote{\url{https://colab.research.google.com/}} is a free Jupyter\footnote{\url{https://jupyter.org}} notebook environment that runs entirely on the cloud, requires no setup and is powered by Google. Jupyter notebook is a cell-based environment that allows to create and share documents containing live code\texttt{}, equations, images and text. It is mostly used with Python, however it has integration with other languages such as R, C++, Scheme or Ruby. Its integration within Google Colab makes it a very easy-to-use tool for prototyping and quick testing. Figure \ref{fig:colab} shows the main user interface.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{archivos/colab}
	\caption{Google Colab web interface.}
	\label{fig:colab}
\end{figure}

Since it is a free environment one may think its not to powerful hardware wise, however this is not the case, it provides more than enough to run deep architectures with ease, although it is not a tool intended for long-running background computation and the system will free resources every 12 hours.
The full hardware specification is shown in table \ref{table:colab}.

\subsection{Docker}
Docker\footnote{\url{https://www.docker.com}} is a 

\subsection{Frameworks}
\gls{dl} has been arising in popularity in the last decade and the most current state-of-the-art \gls{ai} algorithms are based on deep architectures. Because of this, multiple \gls{dl} frameworks have been developed to ease the low level implementation of these algorithms.

\subsubsection{TensorFlow}
TensorFlow\footnote{\url{https://www.tensorflow.org/overview}} is a open source library for numerical computation based on the idea of data flow graphs. In TensorFlow, the graph nodes represent the mathematical operations, while the edges represent the multidimensional data arrays (or tensors) flowing between them, Figure \ref{fig:tensorflow} illustrates an example of a flow graph representation.

\begin{figure}[h]
	\includegraphics[scale=0.3]{archivos/tensorflow.png}
	\centering
	\caption{TensorFlow graph example depicting a simple two-layer convolution + pooling with a fully connected layer for classification at the end.}
	\label{fig:tensorflow}
\end{figure}

TensorFlow was created by the researchers at Google Brain for the purpose of conducting machine learning and deep neural network research, its low level nature allows for a very fine-grained framework that can be use to build any architecture from the ground up and the tensor-graph structure also allows for very easy data distribution on the CPU-GPU.

In a first approach, TensorFlow was considered for its use as the main framework for this project, but it was finally discarded since high level frameworks ease the work and a low level implementation of the networks falls out of the scope of this project.

\subsubsection{Keras}
Keras\footnote{\url{https://keras.io}} is a high level framework written in Python that can use TensorFlow, CNTK or Theano as backend. It was developed to be an easy-to-use framework, allowing for very fast experimentation and prototyping, abstracting the user from some of the more complex low level tasks with a very user friendly interface. This also makes Keras a very good entry framework for beginners that still do not have a solid foundation on deep learning.

Keras provides two different \gls{api}s for different model building approaches. The Sequential API allows to simply stack layer after layer with a very simple and easy-to-use interface. This makes it ideal for models with an input to output data flow. The Functional \gls{api}, however, provides a more flexible way for defining models. With this \gls{api} instances of different layers can be created attached to the model, with this approach, more complex and non-sequential models can be defined.

At the start of this project, Keras was used in order to implement simple neural networks with educational purposes since it is a very easy and intuitive framework. In the end, we discarded it since we believe there are better alternatives that allow for more flexibility.

\subsubsection{PyTorch}
PyTorch\footnote{\url{https://pytorch.org}} is an open source, Python-based, \gls{gpu}-Ready computing package and machine learning framework, just like other frameworks, it provides a Tensor datatype together with all the operations to handle them in both the \gls{gpu} and \glsentryshort{cpu}. This data structure is also compatible with NumPy and other Tensor libraries, which makes it very compatible and easy to integrate.

Another PyTorch feature that is worth mentioning is the modularity, writing new modules for a \gls{nn} is very straightforward and they can be written in both native Python and other NumPy based libraries or with the torch \gls{api}. It also counts with multiple pretrained networks, datasets and well documented examples.

PyTorch is also in continuous development and has been steadily gaining popularity ever since its release back in 2016. In terms of performance, PyTorch is just slightly behind TensorFlow, and outperforms\footnote{\url{https://wrosinski.github.io/deep-learning-frameworks/}} other high level frameworks such as Keras.

\begin{figure}[h]
	\includegraphics[width=\textwidth]{archivos/pytorch.png}
	\centering
	\caption{Worldwide PyTorch and TensorFlow popularity comparison in Google Search.}
	\label{fig:pytorch}
\end{figure}

PyTorch was the framework of choice for this project since it allows for easy prototyping without losing the flexibility to make architectural modifications to the networks. Its syntax is also very easy for anyone that has experience with Python which made it perfect for this project.

\section{Hardware}
\label{sec:hardware}
It is widely known how computationally demanding \gls{dl} algorithms are, specially when dealing with large amounts of data. Also, in order to smoothly run \gls{ue4} while recording and generating all the output images we need a mid to high end computer. In this section we review the ones that have been used in this work.

\subsection{Clarke}

The structure of neural networks where multiple data streams are organized in layers allows for very easy parallelization. Because of this \gls{gpu}s are extremely powerful when executing said algorithms.

The Clarke server was deployed with this in mind and features three different NVIDIA GPUs. The most powerful of them, the Titan X, is aimed towards \gls{dl} computing, the Tesla K40 is also used for computational purposes. The last of them is a Quadro 2000 that is only used for visualization purposes. The full hardware specification for the Clarke server is shown in Figure \ref{table:clarke}.

As for the software, Clarke runs Ubuntu 16.04 with Linux kernel 4.15.0-39-generic for x86\_64 architecture. It also runs Docker, which allows any user to configure its own container with any CUDA / CUDNN version and \gls{dl} framework.

It is also worth mentioning that Clarke was configured for remote access using SSH with public/private key pair authentication. The installed versions are OpenSSH 7.2p2 with OpenSSL 1.0.2 and X11 forwarding was configured for visualization purposes.

\begin{table}[h]
	\centering 
	\begin{tabular}{c p{7cm}}
		\hline
		\multicolumn{2}{c}{Clarke} \\ [0.5ex] 
		\hline
		Motherboard & Asus X99-A \newline Intel X99 Chipset \newline 4x PCIe 3.0/2.0 x 16(x16, x16/ x16, x16/ x16/ x8) \\ 
		\hline
		CPU & Intel(R) Core(TM) i7-6800K CPU @ 3.4GHz \newline 3.4 GHz (3.8 GHz Turbo Boost) \newline 6 cores (12 threads) \newline 140 W TDP \\
		\hline
		GPU (visualization) & NVIDIA GeForce Quadro 2000 \newline 192 CUDA cores \newline 1 GiB of DDR5 Video Memory \newline PCIe 2.0 \newline 62 W TDP \\
		\hline
		GPU (deep learning) & NVIDIA GeForce Titan X \newline 3072 CUDA cores \newline 12 GiB of GDDR5 Video Memory \newline PCIe 3.0 \newline 250 W TDP\\
		\hline
		GPU (compute) & NVIDIA Tesla K40c \newline 2880 CUDA cores \newline 12 GiB of GDDR5 Video Memory \newline PCIe 3.0 \newline 235 W TDP \\
		\hline
		RAM & 2 x 8 GiB G.Skill X DDR4 2400 MHz CL15 \\
		\hline
		Storage (Data) & (RAID1) Seagate Barracuda 7200rpm 3TiB SATA III HDD \\
		\hline
		Storage (OS) & Samsung 850 EVO 250 GiB SATA III SSD \\
		\hline
	\end{tabular}
	\caption{Hardware specification for Clarke.}
	\label{table:clarke}
\end{table}

\subsection{Personal Computer}
During the developing of this work, a personal computer was used in order to run \gls{ue4} and UnrealROX, as well as to generate the data used for the deep learning experimentation. Table \ref{table:pc} shows its full hardware specification.

\begin{table}[h]
	\centering 
	\begin{tabular}{c p{7cm}}
		\hline
		\multicolumn{2}{c}{Personal Computer} \\ [0.5ex] 
		\hline
		Motherboard & Asus STRIX X370-F \newline Amd X370 Chipset \newline 2 x PCIe 3.0/2.0 x16 (x16 or dual x8)  \\ 
		\hline
		CPU & AMD Ryzen‚Ñ¢ 5 1600 CPU @ 3.2GHz \newline 3.2 GHz (3.6 GHz Turbo Boost) \newline 6 cores (12 threads) \newline 140 W TDP \\
		\hline
		GPU & NVIDIA GeForce GTX960 \newline 1024 CUDA cores \newline 2048 MiB of DDR5 Video Memory \newline PCIe 3.0 \newline 120 W TDP \\
		\hline
		RAM & 2 x 8 GiB G.Skill Trident Z DDR4 3200 MHz CL15 \\
		\hline
		Storage (Data) & Seagate Barracuda 7200rpm 2TiB SATA HDD \\
		\hline
		Storage (OS) & Samsung 960 EVO 250GiB NVMe M.2 SSD \\
		\hline

	\end{tabular}
	\caption{Hardware specification for the personal computer.}
	\label{table:pc}
\end{table}

\subsection{Google Colab}
As explained in Subsection \ref{sec:colab}, the Google Colaboratory environment was used in the prototyping and testing process. The hardware specification where this environment runs is shown in Table \ref{table:colab}. Since Colab is run in the cloud and assigns the user a virtual machine, the exact specifications are not known, although it is enough to get an idea of its computational power.

\begin{table}[h]
	\centering 
	\begin{tabular}{c p{7cm}}
		\hline
		\multicolumn{2}{c}{Google Colab} \\ [0.5ex] 
		\hline
		CPU & Intel(R) Core(TM) Xeon CPU @ 2.3GHz \newline 2.3 GHz (No Turbo Boost) \newline 1 core (2 threads) \newline 45MB Cache \\
		\hline
		GPU & NVIDIA Tesla K80 \newline 2496 CUDA cores \newline 12 GiB of GDDR5 Video Memory \newline PCIe 3.0 \newline 300 W TDP \\
		\hline
		RAM & ~12.6 GiB \\
		\hline
		Storage (Data) & ~320 GiB \\
		\hline	
	\end{tabular}
	\caption{Hardware specification for Google Colab instances.}
	\label{table:colab}
\end{table}
